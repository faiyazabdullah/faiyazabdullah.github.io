<!DOCTYPE html>
<html>

<head>
	<title>The Dark Side of AI by Md. Faiyaz Abdullah Sayeedi</title>

	<!-- meta -->
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- css -->
	<link rel="stylesheet" href="../../css/bootstrap.min.css">
	<link rel="stylesheet" href="../../css/ionicons.min.css">
	<link rel="stylesheet" href="../../css/pace.css">
	<link rel="stylesheet" href="../../css/custom.css">
	<link href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css" rel="stylesheet">

	<!-- js -->
	<script src="../../js/jquery-2.1.3.min.js"></script>
	<script src="../../js/bootstrap.min.js"></script>
	<script src="../../js/pace.min.js"></script>
	<script src="../../js/modernizr.custom.js"></script>

	<style>
		article ul,
		article ol {
			font-size: 1.5rem;
			/* slightly larger font size */
			line-height: 1.6;
			margin-bottom: 1rem;
			padding-left: 1.5rem;
		}

		article ul li,
		article ol li {
			margin-bottom: 0.5rem;
			/* spacing between list items */
		}

		article ul li::marker,
		article ol li::marker {
			color: #007BFF;
			/* optional: gives a nice color to bullets/numbers */
		}

		article section {
			margin-top: 1.5rem;
			margin-bottom: 1.5rem;
		}

		article section {
			position: relative;
		}

		article section::before {
			content: "";
			display: block;
			width: 100%;
			height: 2px;
			background-color: #333;
			margin-bottom: 1.5rem;
		}
	</style>
</head>

<body class="graph-paper">
	<!-- navigation -->
	<div class="container">
		<header id="site-header">
			<div class="row">
				<div class="col-md-10 col-sm-10 col-xs-10">
					<div class="logo">
						<h1 style="margin-top: 1.5rem;"><a href="index.html"><b>Md. Faiyaz Abdullah<span
										class="hidden-xs hidden-sm">Sayeedi</span></a></h1>
					</div>
				</div><!-- col-md-4 -->
				<div class="col-md-2 col-sm-2 col-xs-2" style="text-align: right !important;">
					<button type="button" id="trigger-overlay" class="menu-toggle">
						<span class="ion-navicon"></span>
					</button>
				</div>
			</div>
		</header>
	</div>

	<div class="content-body">
		<div class="container">
			<div class="row">
				<div class="site-navigation hidden-xs hidden-sm">
					<nav>
						<ul class="nav-list">
							<li><a href="../../index.html">About</a></li>
							<li><a href="../../articles.html">Articles</a></li>
							<li><a href="../../projects.html">Projects</a></li>
							<li><a href="../../datasets.html">Datasets</a></li>
							<li><a href="../../publications.html">Publications</a></li>
							<li><a href="../../curriculumvita.html">Curriculum vitae</a></li>
							<a href="../../honor_achievement.html">Honor & Achievement</a>
						</ul>
					</nav>
				</div>

				<!-- article section-->
				<main class="col-md-12">
					<article class="post">
						<header class="entry-header">
							<h1 class="entry-title" style="font-size: 48px !important;">
								<a href="single.html" target="_blank">The Dark Side of AI: Understanding Bias in Machine
									Learning Models</a>
							</h1>
							<div class="entry-meta">
								<span class="post-category">ML</span>
								<span class="post-date"><time class="entry-date"
										datetime="2012-11-09T23:15:57+00:00">February 2, 2013</time></span>
							</div>
						</header>
						<figure style="margin: 0; padding: 0; width: 100%; overflow: hidden;">
							<img src="blog_banner.png" alt="banner" style="width: 100%; height: auto; display: block;">
						</figure>
						
						<div class="entry-content clearfix">
							<section>
								<h2>Introduction: Machine Learning Isn’t Always Fair</h2>
								<p>Machine learning is often portrayed as objective and neutral, but real-world
									applications
									tell a different story. From facial recognition systems misidentifying people of
									color
									to hiring algorithms favoring male applicants, bias in AI has emerged as a serious
									concern. As these models increasingly influence decisions in healthcare, finance,
									law
									enforcement, and beyond, their unintended prejudices can lead to unfair and
									sometimes
									dangerous outcomes. But where does this bias come from, and how can we address it?
								</p>
							</section>

							<section>
								<h2>What is Bias in Machine Learning?</h2>
								<p>In machine learning, bias refers to systematic errors that cause unfair outcomes,
									often
									privileging one group over another. This isn’t always due to malicious intent—more
									often, it stems from the data used to train these models. If a dataset reflects
									existing
									societal inequalities, the algorithm trained on it can reinforce those same
									patterns.
									For example, Amazon scrapped an internal hiring tool after it was found to downgrade
									resumes with the word "women’s" in them (<a
										href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G"
										target="_blank" rel="noopener noreferrer">Reuters, 2018</a>).</p>
							</section>

							<section>
								<h2>Types of Bias in ML Models</h2>
								<ul>
									<li><strong>Historical Bias:</strong> When the training data reflects past
										inequalities
										(e.g., biased arrest records).</li>
									<li><strong>Representation Bias:</strong> When certain groups are underrepresented
										in
										the dataset (e.g., few female faces in image data).</li>
									<li><strong>Measurement Bias:</strong> When variables are proxies that misrepresent
										reality (e.g., using ZIP code as a proxy for income or race).</li>
									<li><strong>Aggregation Bias:</strong> When a model assumes a one-size-fits-all
										approach, ignoring subgroup differences.</li>
								</ul>
								<p>Each of these can lead to discriminatory predictions and perpetuate harmful
									stereotypes
									(<a href="https://fairmlbook.org/" target="_blank" rel="noopener noreferrer">Barocas
										et
										al., 2017</a>).</p>
							</section>

							<section>
								<h2>Real-World Examples</h2>
								<ul>
									<li><strong>COMPAS Algorithm (USA):</strong> Used for predicting criminal
										recidivism, it
										was found to overpredict risk for Black defendants (<a
											href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"
											target="_blank" rel="noopener noreferrer">ProPublica, 2016</a>).</li>
									<li><strong>Healthcare AI Tools:</strong> A widely used algorithm underestimated the
										health needs of Black patients due to a flawed assumption that historical
										healthcare
										spending equals need (<a href="https://science.org/doi/10.1126/science.aax2342"
											target="_blank" rel="noopener noreferrer">Obermeyer et al., 2019</a>).</li>
									<li><strong>Face Recognition Failures:</strong> MIT Media Lab found that commercial
										facial recognition systems misclassified darker-skinned women up to 34.7% of the
										time, compared to 0.8% for lighter-skinned men (<a
											href="https://proceedings.mlr.press/v81/buolamwini18a.html" target="_blank"
											rel="noopener noreferrer">Buolamwini and Gebru, 2018</a>).</li>
								</ul>
							</section>

							<section>
								<h2>How to Detect and Mitigate Bias</h2>
								<p>Fighting bias starts with acknowledging it and designing for fairness. Key strategies
									include:</p>
								<ul>
									<li><strong>Dataset Audits:</strong> Check for class imbalances and skewed
										representation.</li>
									<li><strong>Fairness Metrics:</strong> Use metrics like demographic parity, equal
										opportunity, or disparate impact to evaluate bias (<a
											href="https://developers.google.com/machine-learning/fairness-overview/"
											target="_blank" rel="noopener noreferrer">Google AI Fairness</a>).</li>
									<li><strong>Model Debiasing Techniques:</strong>
										<ul>
											<li><em>Reweighting or Resampling:</em> Balance data distributions.</li>
											<li><em>Adversarial Debiasing:</em> Use auxiliary networks to reduce
												correlation
												with sensitive attributes.</li>
											<li><em>Post-processing Adjustments:</em> Modify outputs to ensure fairness.
											</li>
										</ul>
									</li>
								</ul>
								<p>Open-source libraries like <a href="https://aif360.mybluemix.net/" target="_blank"
										rel="noopener noreferrer">IBM’s AI Fairness 360</a> and <a
										href="https://fairlearn.org/" target="_blank"
										rel="noopener noreferrer">Fairlearn</a> provide tools to implement these methods
									in
									practice.</p>
							</section>

							<section>
								<h2>Bias Isn’t Just Technical — It’s Ethical</h2>
								<p>Addressing bias isn’t just a technical fix—it’s a moral responsibility. Developers
									must
									think critically about how their models are built, whom they benefit, and whom they
									might harm. This includes integrating ethical review boards, engaging with affected
									communities, and ensuring transparency and explainability in AI systems. The <a
										href="https://artificialintelligenceact.eu/" target="_blank"
										rel="noopener noreferrer">European Union’s proposed AI Act</a> and initiatives
									like
									the <a href="https://www.oecd.org/going-digital/ai/principles/" target="_blank"
										rel="noopener noreferrer">OECD AI Principles</a> reflect growing recognition of
									this
									need.</p>
							</section>

							<section>
								<h2>The Future: Building Inclusive AI</h2>
								<p>As AI systems become more powerful and pervasive, fairness must be a foundational
									design
									principle. The next frontier in machine learning isn’t just better accuracy—it’s
									equitable impact. By embracing diverse datasets, interdisciplinary collaboration,
									and
									robust accountability frameworks, we can work toward machine learning that reflects
									our
									highest human values, not our worst historical patterns.</p>
							</section>

							<section>
								<h2>Final Thoughts</h2>
								<p>Bias in machine learning is a pressing issue that can’t be ignored. From training
									data to
									deployment, every step in the ML pipeline must be scrutinized to ensure that models
									serve all people fairly. In the end, building better AI isn’t just about smarter
									machines—it’s about a more just world.</p>
							</section>
						</div>
					</article>
				</main>

			</div>
		</div>

		<!-- Contact Form -->
		<div class="container" style="margin-top: 6rem;">
			<div class="row">
				<h2 class="title text-center">Let's Connect</h2>
				<div class="col-md-8">
					<article class="post" style="margin-top: 2rem;">
						<div class="entry-content clearfix">
							<form action="mailto:faiyazabdullah114708@gmail.com" method="post" enctype="text/plain"
								class="contact-form">
								<div class="row">
									<div class="col-md-12">
										<input type="text" name="name" placeholder="Name" required>
										<input type="email" name="email" placeholder="Email" required>
										<input type="text" name="subject" placeholder="Subject" required>
										<textarea name="message" rows="7" placeholder="Your Message"
											required></textarea>
										<div class="text-center">
											<button class="btn-send btn-5 btn-5b ion-ios-paperplane"><span>Drop Me a
													Line</span></button>
										</div>
									</div>
								</div> <!-- row -->
							</form>
						</div>
					</article>

					<div class="col-md-12" style="margin-top: 6rem;">
						<ul class="social">
							<li class="facebook"><a href="https://www.facebook.com/faiyazabdullah336908"
									target="_blank"><span class="ion-social-facebook"></span></a></li>
							<li class="linkedin"><a href="https://www.linkedin.com/in/mdfaiyazabdullahsayeedi/"
									target="_blank"><span class="ion-social-linkedin"></span></a></li>
							<li class="github"><a href="https://github.com/faiyazabdullah" target="_blank"><span
										class="ion-social-github"></span></a></li>
						</ul>
					</div>
				</div>
				<aside class="col-md-4">
					<div class="widget widget-info">
						<h3 class="widget-title">Personal Information</h3>
						<ul>
							<li>
								<p>phone: +8801704054900</p>
							</li>
							<li>
								<p>email: faiyazabdullah114708@gmail.com</p>
							</li>
							<li>
								<p>address: Kasba, Chittagong, Bangladesh</p>
							</li>
						</ul>
					</div>
					<div class="widget widget-link">
						<h3 class="widget-title">Social Links</h3>
						<ul>
							<li>
								<a href="https://www.linkedin.com/in/mdfaiyazabdullahsayeedi/"
									target="_blank">linkedin/mdfaiyazabdullahsayeedi</a>
							</li>
							<li>
								<a href="https://scholar.google.com/citations?user=gLTfVpwAAAAJ&hl=en"
									target="_blank">scholar/mdfaiyazabdullahsayeedi</a>
							</li>
							<li>
								<a href="https://github.com/faiyazabdullah"
									target="_blank">github/mdfaiyazabdullahsayeedi</a>
							</li>
							<li>
								<a href="https://www.researchgate.net/profile/Md-Sayeedi"
									target="_blank">researchgate/mdfaiyazabdullahsayeedi</a>
							</li>
							<li>
								<a href="https://orcid.org/0009-0007-3079-7806"
									target="_blank">orcid/mdfaiyazabdullahsayeedi</a>
							</li>
							<li>
								<a href="https://www.facebook.com/faiyazabdullah336908"
									target="_blank">facebook/faiyazabdullah</a>
							</li>
						</ul>
					</div>
					<div class="widget widget-nav">
						<h3 class="widget-title">Site Navigation</h3>
						<ul>
							<li>
								<a href="../../index.html">About</a>
							</li>
							<li>
								<a href="../../articles.html">Articles</a>
							</li>
							<li>
								<a href="../../projects.html">Projects</a>
							</li>
							<li>
								<a href="../../datasets.html">Datasets</a>
							</li>
							<li>
								<a href="../../publications.html">Publications</a>
							</li>
							<li>
								<a href="../../curriculumvita.html">Curriculum vitae</a>
							</li>
							<li>
								<a href="../../honor_achievement.html">Honor & Achievement</a>
							</li>
						</ul>
					</div>
				</aside>
			</div>
		</div>
	</div>

	<!-- Footer -->
	<footer id="site-footer">
		<div class="container">
			<div class="row">
				<div class="col-md-12">
					<p class="copyright">&copy; 2025 Md. Faiyaz Abdullah Sayeedi. Powered by <a
							href="https://github.com/UIU-Developers-Hub">@UIU Developers Hub</a>. Hosted by GitHub
						Pages.</p>
				</div>
			</div>
		</div>
	</footer>

	<!-- Mobile Menu -->
	<div class="overlay overlay-hugeinc">
		<button type="button" class="overlay-close"><span class="ion-ios-close-empty"></span></button>
		<nav>
			<ul>
				<li>
					<a href="../../index.html">About</a>
				</li>
				<li>
					<a href="../../articles.html">Articles</a>
				</li>
				<li>
					<a href="../../projects.html">Projects</a>
				</li>
				<li>
					<a href="../../datasets.html">Datasets</a>
				</li>
				<li>
					<a href="../../publications.html">Publications</a>
				</li>
				<li>
					<a href="../../curriculumvita.html">Curriculum vitae</a>
				</li>
				<li>
					<a href="../../honor_achievement.html">Honor & Achievement</a>
				</li>
			</ul>
		</nav>
	</div>

	<!-- whatsapp button -->
	<a href="https://wa.me/+8801704054900?text=Hello%20I%20want%20to%20know%20more..." class="whatsapp-float"
		target="_blank" aria-label="Chat on WhatsApp" style="background-color: rgb(225, 225, 225) !important;">
		<img src="https://img.icons8.com/ios-filled/50/25D366/whatsapp.png" alt="WhatsApp Chat"
			title="Reach me on WhatsApp" style="background-color: rgb(225, 225, 225) !important;" />
	</a>

	<script src="../../js/script.js"></script>
	<!-- jQuery and JS logic -->
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
</body>

</html>